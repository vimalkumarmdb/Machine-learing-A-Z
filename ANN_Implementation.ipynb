{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 3:13].values\n",
    "y = df.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\idp\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Anaconda3\\envs\\idp\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:385: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 2.2800000e+02, ..., 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0134888e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 2.1700000e+02, ..., 0.0000000e+00,\n",
       "        1.0000000e+00, 1.1254258e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.1100000e+02, ..., 1.0000000e+00,\n",
       "        0.0000000e+00, 1.1393157e+05],\n",
       "       ...,\n",
       "       [0.0000000e+00, 0.0000000e+00, 3.1800000e+02, ..., 0.0000000e+00,\n",
       "        1.0000000e+00, 4.2085580e+04],\n",
       "       [0.0000000e+00, 1.0000000e+00, 3.8100000e+02, ..., 1.0000000e+00,\n",
       "        0.0000000e+00, 9.2888520e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 4.0100000e+02, ..., 1.0000000e+00,\n",
       "        0.0000000e+00, 3.8190780e+04]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's make the ANN!\n",
    "* Importing the Keras libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialising the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adding the input layer and the first hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\idp\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\idp\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\idp\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adding the output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\idp\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fitting the ANN to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\idp\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\idp\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 3s 346us/step - loss: 0.4892 - accuracy: 0.7956\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 2s 215us/step - loss: 0.4284 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 2s 215us/step - loss: 0.4233 - accuracy: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.4194 - accuracy: 0.8144\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 2s 212us/step - loss: 0.4171 - accuracy: 0.8236\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 2s 213us/step - loss: 0.4152 - accuracy: 0.8267\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 2s 210us/step - loss: 0.4136 - accuracy: 0.8291\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.4123 - accuracy: 0.8313\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 2s 211us/step - loss: 0.4111 - accuracy: 0.8309\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 2s 211us/step - loss: 0.4105 - accuracy: 0.8325\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.4091 - accuracy: 0.8338\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 2s 209us/step - loss: 0.4087 - accuracy: 0.8341\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.4079 - accuracy: 0.8344\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 2s 216us/step - loss: 0.4073 - accuracy: 0.8339\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.4067 - accuracy: 0.8347\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.4066 - accuracy: 0.8353\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.4059 - accuracy: 0.8344\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 2s 244us/step - loss: 0.4052 - accuracy: 0.8342\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.4049 - accuracy: 0.8338\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.4051 - accuracy: 0.8354\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 2s 214us/step - loss: 0.4045 - accuracy: 0.8347\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 2s 265us/step - loss: 0.4042 - accuracy: 0.8355\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 2s 248us/step - loss: 0.4040 - accuracy: 0.8354\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 2s 256us/step - loss: 0.4036 - accuracy: 0.8354\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 2s 278us/step - loss: 0.4036 - accuracy: 0.8342\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 2s 241us/step - loss: 0.4038 - accuracy: 0.8365\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.4029 - accuracy: 0.8354\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 2s 222us/step - loss: 0.4029 - accuracy: 0.8319\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 2s 220us/step - loss: 0.4031 - accuracy: 0.8359\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 2s 273us/step - loss: 0.4029 - accuracy: 0.8355\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.4030 - accuracy: 0.8350\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.4028 - accuracy: 0.8342\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.4023 - accuracy: 0.8359\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 2s 239us/step - loss: 0.4025 - accuracy: 0.8350\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.4028 - accuracy: 0.8344\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.4023 - accuracy: 0.8351\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 2s 224us/step - loss: 0.4023 - accuracy: 0.8356\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 2s 254us/step - loss: 0.4024 - accuracy: 0.8353\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 2s 278us/step - loss: 0.4020 - accuracy: 0.8360\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 2s 287us/step - loss: 0.4019 - accuracy: 0.8354\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 2s 222us/step - loss: 0.4022 - accuracy: 0.8354\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.4018 - accuracy: 0.8347\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.4021 - accuracy: 0.8353\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 2s 217us/step - loss: 0.4020 - accuracy: 0.8346\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 2s 218us/step - loss: 0.4015 - accuracy: 0.8346\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 2s 219us/step - loss: 0.4017 - accuracy: 0.8342\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 2s 224us/step - loss: 0.4016 - accuracy: 0.8351\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.4017 - accuracy: 0.8350\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 2s 226us/step - loss: 0.4019 - accuracy: 0.8351\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 2s 258us/step - loss: 0.4013 - accuracy: 0.8349\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 2s 231us/step - loss: 0.4012 - accuracy: 0.8354\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.4017 - accuracy: 0.8341\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.4013 - accuracy: 0.8349\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 2s 279us/step - loss: 0.4017 - accuracy: 0.8354\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.4014 - accuracy: 0.8351\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.4014 - accuracy: 0.8346\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.4014 - accuracy: 0.8324\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.4008 - accuracy: 0.8342\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 2s 296us/step - loss: 0.4013 - accuracy: 0.8350\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.4010 - accuracy: 0.8344\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.4011 - accuracy: 0.8341\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.4010 - accuracy: 0.8353\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 2s 236us/step - loss: 0.4012 - accuracy: 0.8360\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 2s 238us/step - loss: 0.4012 - accuracy: 0.8351\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.4007 - accuracy: 0.8342\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.4009 - accuracy: 0.8350\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 2s 233us/step - loss: 0.4010 - accuracy: 0.8354\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 2s 249us/step - loss: 0.4007 - accuracy: 0.8346\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 2s 221us/step - loss: 0.4006 - accuracy: 0.8353\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.4003 - accuracy: 0.8354\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 2s 226us/step - loss: 0.4012 - accuracy: 0.8354\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 2s 224us/step - loss: 0.4010 - accuracy: 0.8334\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 2s 256us/step - loss: 0.4011 - accuracy: 0.8335\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.4007 - accuracy: 0.8344\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 2s 225us/step - loss: 0.4004 - accuracy: 0.8356\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 2s 227us/step - loss: 0.4009 - accuracy: 0.8342\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.4007 - accuracy: 0.8351\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 2s 239us/step - loss: 0.4005 - accuracy: 0.8353\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.4002 - accuracy: 0.8344\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 2s 275us/step - loss: 0.3999 - accuracy: 0.8361\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 2s 239us/step - loss: 0.4004 - accuracy: 0.8350\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 2s 272us/step - loss: 0.4005 - accuracy: 0.8349\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4005 - accuracy: 0.83 - 2s 247us/step - loss: 0.4005 - accuracy: 0.8356\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 2s 238us/step - loss: 0.4004 - accuracy: 0.8366\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 2s 235us/step - loss: 0.4007 - accuracy: 0.8353\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 2s 234us/step - loss: 0.4005 - accuracy: 0.8350\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 2s 254us/step - loss: 0.4004 - accuracy: 0.8353\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 2s 305us/step - loss: 0.4004 - accuracy: 0.8347\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 2s 232us/step - loss: 0.3999 - accuracy: 0.8347\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 2s 232us/step - loss: 0.4004 - accuracy: 0.8365\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 2s 230us/step - loss: 0.4003 - accuracy: 0.8351\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 2s 228us/step - loss: 0.4003 - accuracy: 0.8354\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 2s 274us/step - loss: 0.4005 - accuracy: 0.8341\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 2s 232us/step - loss: 0.3998 - accuracy: 0.8355\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 2s 268us/step - loss: 0.4000 - accuracy: 0.8336\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 2s 251us/step - loss: 0.4000 - accuracy: 0.8350\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 2s 255us/step - loss: 0.4004 - accuracy: 0.8355\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 2s 248us/step - loss: 0.4001 - accuracy: 0.8353\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 2s 240us/step - loss: 0.3998 - accuracy: 0.8350\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 2s 235us/step - loss: 0.3996 - accuracy: 0.8353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x217c699ca90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Testset results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  83.95\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \",accuracy_score(y_test,y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sn.heatmap(cm, annot=True,  fmt='.2f', xticklabels = [\"Yes\", \"No\"] , yticklabels = [\"Yes\", \"No\"],)\n",
    "plt.ylabel('True label',fontsize=12)\n",
    "plt.xlabel('Predicted label',fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
